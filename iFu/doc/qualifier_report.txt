ifu初赛设计报告

1. 项目概述
1.1 项目背景
    本项目是复旦大学在第八届龙芯杯全国大学生计算机系统能力培养大赛（NSCSCC 2024）团队赛的参赛作品
    基于loongArch32架构，我们在FPGA平台上面实现了一个乱序多发射CPU，可以通过发布包中全部的功能测试以及性能测试
1.2 开发语言
    本项目使用新型硬件语言——chisel来编写。
    Chisel是一种开源，在RTL级别描述数字电子电路的硬件描述语言，可以在FPGA实验平台进行方便地开发。
    Chisel将硬件构造原语添加到Scala编程语言中，为设计者提供了现代编程语言的能力，可以编写复杂的、可参数化的电路生成器，从而生成可综合的Verilog。这种生成器方法能够创建可重用的组件和库，例如Chisel标准库中的FIFO队列和仲裁器，从而提高设计中的抽象级别，同时保持精细的控制。
    此外，chisel的类，函数式编程，参数传递都更为灵活，可以大大提高编写复杂逻辑的开发效率以及可读性。

2. 设计思路
2.1 CPU架构
    iFuCore是一个乱序多发射CPU，实现前后端解耦，通过fetch Buffer来进行前后端之间指令的传递。
    2.1.1前端
    宽度为4，主要任务包括分支预测以及取指令,另外还带有取指令缓冲 (Fetch buffer) 来联系前后端。
    由于令后端的uop携带完整的PC会使得后端数据流负担很大，因此我们将pc信息保留在前端的fetchTarget Queue里面，后端如有需要（例如，jirl，branch类指令），
    会通过自己uop持有的idx  去取出pc使用，另外我们注意到branch类指令计算目标地址所需的imm和pc信息在前端取出inst时便可全部得到，因此前端
    增加一个预译码(predecode)阶段及时计算并纠正target_pc，于是后端只需要判断是否taken即可。

    我们不将译码阶段作为真正的一级流水段，因为前端三周期的分支预测，和取指已经很长，而译码作为前后端衔接的组合逻辑部分，在我们的时序水平下可以接受，因此
    我们尽可能减少流水线的级数以减轻分支预测损失

    2.1.2 译码
    译码阶段是组合逻辑,将前端获得的指令进行译码，生成uop，由于没有独立流水级，需要保证每个指令对应一个uop
    ，同时负责检测出其中的指令异常

    2.1.3后端
    后端包括寄存器重命名，分派，发射，执行，提交几个阶段

    寄存器重命名

    分派

    发射

    发射宽度为3，分为两个发射队列，包括计算和访存两部分，计算流水线有三个计算单元，可以执行csr，乘除法，跳转判断，以及普通运算指令
    特别地，我们通过chisel搭建核内性能计数器之后，发现很多测试点的访存指令占比很大(40%)，访存导致的阻塞对于乱序执行是很大的损失，因此我们尝试搭建
    高效率的，两条流水线的非阻塞dcache以及包括访存内部转发的Lsu，使得CPU处理访存的效率大大加强，这会导致Lsu板上面积很大，对频率提升有影响，但是我们
    发现其对ipc带来的提升收益更大，因此选择这种结构。

    

    执行

    提交    


2.2 架构优化设计

    2.2.1缓存设计
    icache：
    我们经过前后端的指令数据分析，发现后端的处理速度要大于前端的供指速度，我们前端的供值能力成为瓶颈，因此我们需要保障icache为8路，以匹配分支预测和后端的需求
    icache采用VIPT的匹配策略，LRU的替换策略 每路为4KB
    
    dcache
    dcache采用PIPT的匹配模式（在地址计算的时候会同时用一周期进行地址翻译），将地址和dcache执行进行解耦，以减轻频率负担，dcache访存分三级执行，拥有两条流水线，同周期处理至多一条store指令，最多两条load指令
    dcache为4路，64Sets，每行16字（AXI协议支持的单次最大burst长度），每路为4KB

    dcache 是具有两条流水线的非阻塞缓存，在s0进行读meta，s1判断命中以及发起data的读取请求，s2进行可能的data写请求
    同一拍允许至多一条store指令，最多两条load指令，提高了访存请求的吞吐量，同时由于非阻塞的特性，在进行重填行的同时，也可以允许
    其他cache行有关的访存请求正常执行，大大减少了访存请求的阻塞时间。

    我们在sha，stream_copy，memcpy等测试点的性能有显著优势
    特别是新增测试点my_memcmp，在强访存架构的支持下，我们的加速比可以达到6.5

    2.2.2 分支预测器设计
    分支预测使用三阶段分支预测，s1通过一个ubtb进行next Line Predict
    s2进行btb的地址判断，以及bim的判断
    s3输出通过13位局部历史预测器的跳转结果，由于局部历史学习时间较长，其只有具备一定置信度，才可以推翻s2bim给出的跳转结果。
    同时，s3还会通过预译码严格确定分支预测跳转的目标地址，由于预译码结果一定正确，因此如有不同，可以推翻前面btb给出的target。

    分支预测器内部存储的target是目标pc的低位部分，输出时会与请求pc的高位部分拼接，以得到完整的预测目标pc，这样可以避免
    offset计算开销，同时减轻预测器存储负担。

    faubtb
    负责进行next line predict，当周期根据传入的pc进行预测，给出预测目标的pc低位，以及是否跳转
    faubtb是4路全相联结构，以传入pc所在的一拍为单位进行预测

    bim
    两周期预测器，维护512个两位计数器,根据pc去索引，给出s2预测的跳转结果

    BTB
    2路64项的BTB，根据pc的低位进行索引，给出s2预测的跳转目标低位

    lh

    2.2.3 推测唤醒



3. 结果展示
3.0 指令支持
    我们实现了龙芯32位指令集手册中要求的指令，这包括：

3.1 功能测试
    经过vivado编译综合，本cpu可以通过全部58个功能测试
3.2 性能测试
    在perf_test中，我们的cpu可以通过全部的性能测试，其中sha，stream_copy，memcpy等测试点的性能有显著优势
    

4. 参考资料
本项目的设计和开发过程中参考和借鉴了包括但不限于以下资料：
• 超标量处理器设计. 姚永斌
• chisel 文档： https://www.chisel-lang.org/docs
• Mariver 设计文档及仓库： https://github.com/HIT-MaRiver-mips/cpucore-mariver
• 龙芯32位指令集手册:https://www.loongson.cn/uploads/images/2023041918133323805.%E9%BE%99%E8%8A%AF%E6%9E%B6%E6%9E%84%E5%8F%82%E8%80%83%E6%89%8B%E5%86%8C%E5%8D%B7%E4%B8%80_r1p03.pdf
• The Berkeley Out-of-Order Machine (BOOM)
文档： https://docs.boom-core.org/en/latest/sections/intro-overview/boom.html
仓库： https://github.com/riscv-boom/riscv-boom






----------------------------------------------ZenCove----------------------------------------------
2 CPU 架构
2.1 基本架构
ZenCove 采用乱序多发射的基本架构，发射数量为可配置的参数。在标准参数下为 5 发射。乱序多发射流水线大
致可以分为前端流水线与后端流水线，以重排序缓存 (ROB) 和发射队列为分隔。为了满足精确异常的要求，在前端与
后端执行完指令后，由 ROB 异步地将指令提交。
2.1.1 前端
前端流水线共五级，包括两级取指令、指令译码、寄存器重命名、指令派发。
取指令 1 这一阶段进行 PC 的 TLB 查询与地址翻译，并进行 I-Cache 查询的第一阶段。分支预测在此阶段查询分支
目标缓存 (BTB) 与预测历史表 (PHT) 。
取指令 2 这一阶段进行 I-Cache 查询的第二阶段，并对 Cache 缺失的情况进行填充。分支预测在此阶段形成预测结
果，预测目标 PC。这一阶段之后将指令装入取指令缓冲 (Fetch buffer) ，这样可以平衡取指令速度与指令派发速度，
也将取指令速度“削峰填谷”，减少气泡与暂停的出现。
指令译码 指令译码阶段取出取指令缓冲中的若干条指令（宽度为可配置参数），进行译码，翻译成微码 (Micro op,
µop) 。由于 MIPS 为 RISC 架构，我们保证每条指令只生成一个 µop。
寄存器重命名 ZenCove 采用显式重命名，即只采用物理寄存器重命名逻辑寄存器，将寄存器映射存储在重命名映射
表 (Rename alias table, RAT) 中。由于精确异常回滚的需要，重命名映射表需要存储推测性的和架构性的两份。采用
FIFO 管理的空闲寄存器列表 (free list) 管理可以被分配的物理寄存器，在此阶段给需要写寄存器的指令分配物理寄存
器。若需要分配而 free list 已空，则需要暂停此阶段。
指令派发 此阶段根据指令类型将指令装入不同的发射队列。 ROB 的装入可以在此阶段，也可以在寄存器重命名阶段。
22.1.2 后端
后端流水线数量等于发射宽度。在默认配置下，有三条不完全对称的整数流水线，一条乘除法流水线，一条访存
流水线，组成 5 发射。所有后端流水线都由发射、读寄存器、执行、写回 4 个主要阶段组成，其中访存流水线的执行
由于 D-Cache 访问的需要扩展成了两个阶段。
发射 ZenCove 采用分布式的发射队列，有整数发射队列、乘除法发射队列、访存发射队列 3 个发射队列。整数发射队
列有三条整数流水线共同取指令发射，乘除法与访存各自面向一条流水线。整数发射采用纯乱序的方式，三条流水线
共同选择避免重复发射；乘除法与访存目前均采用纯顺序的方式，因此它们都是 FIFO 队列，但是不同发射队列的指
令之间仍然构成了乱序。整数流水线在此阶段唤醒整数发射队列中的指令，使得在前传下整数指令写后读 (RAW) 相
关可以背靠背执行。
读寄存器 此阶段读物理寄存器堆，并进行寄存器的前传。整数流水线在此阶段唤醒与它 RAW 相关的后续指令，使
得所有指令均可以间隔一个气泡读到整数指令的结果。
执行 每一条整数流水线均包括相同的算术逻辑单元 (ALU)，而仅有一条整数流水线包括比较器，读协处理器 0 (CP0)
的功能。乘除法流水线在此阶段计算乘法、除法，以及处理 Hi/Lo 寄存器的读写。访存流水线的执行第一阶段进行 TLB
查询与地址翻译，并进行 D-Cache 查询的第一阶段。第二阶段进行 D-Cache 查询的第二阶段，并对 Cache 读缺失的
情况进行填充。同时对于 store 指令和 uncached 地址段的 load 指令，由于执行会对处理器状态造成不可恢复的改变，
装入 store buffer 等待提交后执行。从 store buffer 发射的指令，在此阶段进行 D-Cache 的写，进行写缺失填充，或
对 uncached 情况进行直接设备访问。
写回 此阶段将执行结果分别写入物理寄存器和 ROB。
2.1.3 指令提交
ROB 读取未提交的指令，判断指令是否可以提交，按顺序提交至多提交宽度条指令，并对分支预测错误、异常与
中断、处理器状态回滚、 store buffer 激活等需要提交时处理的情况进行处理。
为了降低硬件复杂度同时简化特殊情况的处理，我们限制了只有 0 号提交口可以处理特殊的指令（如 Conditional
Move, Uncached Load 等）和特殊的情况（如异常，分支预测错误等需要重置处理器状态的情况）。
2.2 指令支持
ZenCove 共实现了 92 条 MIPS 指令，基本涵盖了单核 MIPS32 release 1 处理器除浮点外所需的指令，按照功能
划分如下：
• 算术指令： ADD, ADDI, ADDIU, ADDU, CLO, CLZ, DIV, DIVU, MADD, MADDU, MSUB, MSUBU, MUL,
MULT, MULTU, SUB, SUBU
• 逻辑指令： AND, ANDI, NOR, OR, ORI, SLL, SLLV, SRA, SRAV, SRL, SRLV, XOR, XORI
• 访存指令： LB, LBU, LH, LHU, LW, LWL, LWR, SB, SH, SW, SWL, SWR
• 分支指令： BEQ, BGEZ, BGEZAL, BGTZ, BLEZ, BLTZ, BLTZAL, BNE, J, JAL, JALR， JALR.HB, JR, JR.HB
• 自陷指令： TEQ, TEQI, TGE, TGEI, TGEIU, TGEU, TLT, TLTI, TLTIU, TLTU, TNE, TNEI
• 移动指令： LUI, MFHI, MFLO, MOVN, MOVZ, MTHI, MTLO, SLT, SLTI, SLTU, SLTIU
• 特权指令： BREAK, CACHE, ERET, MFC0, MTC0, SYSCALL, TLBP, TLBR, TLBWI, TLBWR, WAIT
• 其他指令： PERF, SYNC
3由于 axi 总线不支持以 3 byte 为访问粒度进行读写，故 unaligned load/store 指令（LWL/LWR/SWL/SWR) 不
支持以 uncached 方式进行读写。

1.4 参考资料
本项目的设计和开发过程中参考和借鉴了包括但不限于以下资料：
• 超标量处理器设计. 姚永斌
• The Berkeley Out-of-Order Machine (BOOM)
文档： https://docs.boom-core.org/en/latest/sections/intro-overview/boom.html
仓库： https://github.com/riscv-boom/riscv-boom
• SpinalHDL 文档： https://spinalhdl.github.io/SpinalDoc-RTD/master/index.html
• Vexriscv 仓库： https://github.com/SpinalHDL/VexRiscv
• NonTrivial-MIPS 仓库： https://github.com/trivialmips/nontrivial-mips
• LLCL-MIPS 仓库： https://github.com/huang-jl/LLCL-MIPS
• MIPS® Architecture For Programmers I, II, III. Imagination Technologies LTD.
• 各外设使用手册. 相关厂商


2.8 微架构优化
ZenCove 微架构在设计时，为了进一步提高指令执行效率，加入了推测唤醒和流水线前传两个执行方法。
这两个方法可以有效减少指令在各个执行流水线中冲突时暂停的周期，从而有效降低 CPI。
2.8.1 推测唤醒
Load 指令与需要读 load 结果的后续指令的 RAW 依赖是程序执行中常见的依赖，即 load-use 依赖。
由于 load 指令执行周期数不确定，尤其是在 cache 缺失时，因此只能在访存流水线的执行 2 (MEM2) 阶段进行唤
醒。这导致 load-use 要空 3 个气泡。即使是乱序执行也通常找不到这么多不相关指令，导致 load 经常导致气泡出现。
而 cache 命中时 load 执行周期时确定的，因此在 MEM1 阶段即可唤醒，那么 cache 命中时 load-use 只需要空 2
个气泡，通常就可以找到其它不相关指令进行填充。
但在 cache 缺失时这一唤醒就是错误的，后续例如整数指令就不能及时读到正确的寄存器结果。
因此我们在 cache 缺失时简单地将所有流水线暂停。考虑到 cache 缺失应当是小概率事件，并且 cache 缺失本就
不可避免地导致处理器执行暂停，因此总体而言还是能够做到性能提升。
2.8.2 流水线前传
由于发射宽度较宽，本处理器没有实现所有流水线之间的前传，但对最常用的整数流水线之间实现了完全的前传。
在没有前传的情况下，整数指令与其它指令之间的 RAW 依赖需要空一个气泡，整数流水线的前传使得整数指令之间
的 RAW 依赖可以背靠背执行，达到了最高的执行效率。
2.9 外部接口
CPU 采用 AXI4 总线与外部相连，流水线直接访问 Instruction bus， Cached data bus， Uncached data bus 三条
总线，对于需要暴露一条总线的，采用 AXI crossbar IP 做 3*1 crossbar。
按照 MIPS 手册， CPU 支持 6 个外部中断。